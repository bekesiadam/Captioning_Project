{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e9550c",
   "metadata": {},
   "source": [
    "## Szükséges csomagok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc43574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\miniconda3\\envs\\main_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import SiglipProcessor, SiglipModel\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a16f23",
   "metadata": {},
   "source": [
    "## Modell és az adatok betöltése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_5460\\1434608005.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_5460\\1434608005.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Betöltés\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SiglipModel.from_pretrained(\"google/siglip-base-patch16-224\").to(device)\n",
    "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
    "\n",
    "# Adatok\n",
    "embeddings = torch.load(\"../data/image_embeddings_siglip.pt\")\n",
    "infos = torch.load(\"../data/image_info_siglip.pt\")\n",
    "with open(\"../data/custom_captions.json\", encoding=\"utf-8\") as f:\n",
    "    class_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996fc89",
   "metadata": {},
   "source": [
    "## Képek csoportosítása osztályonként"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429609bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ez egy szótár, amely minden osztályhoz hozzárendeli a hozzá tartozó képek embeddingjeit\n",
    "class_to_embeddings = {}\n",
    "\n",
    "for idx, info in enumerate(infos):\n",
    "    label = str(info['label'])\n",
    "    if label not in class_to_embeddings:\n",
    "        class_to_embeddings[label] = []\n",
    "    class_to_embeddings[label].append(embeddings[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13a32f",
   "metadata": {},
   "source": [
    "## Osztályon belüli hasonlóságok számítása\n",
    "\n",
    "Minden osztály esetén kiszámoljuk az osztályon belüli képpárok átlagos cosine similarity értékét, majd elmentjük JSON fájlba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiszámoljuk az osztályok közötti átlagos cosine similarity-t\n",
    "similarities_per_class = {}\n",
    "\n",
    "for class_id, class_embeddings in class_to_embeddings.items():\n",
    "    embeddings_tensor = torch.stack(class_embeddings)\n",
    "    \n",
    "    # Kiszámítjuk a cosine similarity mátrixot az osztályon belül\n",
    "    similarity_matrix = cosine_similarity(embeddings_tensor.cpu().numpy())\n",
    "    \n",
    "    # Az összes párra átlagos cosine similarity-t számolunk\n",
    "    upper_triangle_indices = np.triu_indices(similarity_matrix.shape[0], k=1)\n",
    "    \n",
    "    avg_similarity = similarity_matrix[upper_triangle_indices].mean()\n",
    "    similarities_per_class[class_id] = avg_similarity.item()  # float32 -> float64\n",
    "\n",
    "# Eredmény mentése fájlba\n",
    "output_file = \"../data/intra_class_similarities.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(similarities_per_class, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49fa73",
   "metadata": {},
   "source": [
    "## Osztályok közötti hasonlóságok számítása\n",
    "\n",
    "Két osztály minden képpárjára kiszámoljuk a cosine similarity értékét. Az azonos osztályhoz tartozó képek esetén kizárjuk az önmagukkal való összehasonlítást."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Képosztályok közötti inter cosine similarity kiszámítása\n",
    "inter_class_similarities = {}\n",
    "\n",
    "class_ids = list(class_to_embeddings.keys())\n",
    "\n",
    "for class_id_1 in class_ids:\n",
    "    embeddings_class_1 = torch.stack(class_to_embeddings[class_id_1]).cpu().numpy()\n",
    "    inter_class_similarities[class_id_1] = {}\n",
    "\n",
    "    for class_id_2 in class_ids:\n",
    "        embeddings_class_2 = torch.stack(class_to_embeddings[class_id_2]).cpu().numpy()\n",
    "\n",
    "        if class_id_1 == class_id_2:\n",
    "            # Osztályon belül: saját magukkal való hasonlóságok kizárása (diagonálon kívüli elemek)\n",
    "            similarity_matrix = cosine_similarity(embeddings_class_1)\n",
    "            if similarity_matrix.shape[0] > 1:\n",
    "                upper_triangle_indices = np.triu_indices(similarity_matrix.shape[0], k=1)\n",
    "                avg_similarity = similarity_matrix[upper_triangle_indices].mean()\n",
    "            else:\n",
    "                avg_similarity = 1.0  # Ha csak 1 kép van az osztályban, nincs mit számolni\n",
    "        else:\n",
    "            # Két különböző osztály: minden páron számolunk\n",
    "            similarity_matrix = cosine_similarity(embeddings_class_1, embeddings_class_2)\n",
    "            avg_similarity = similarity_matrix.mean()\n",
    "\n",
    "        inter_class_similarities[class_id_1][class_id_2] = float(avg_similarity)\n",
    "\n",
    "# Eredmény mentése fájlba\n",
    "output_file = \"../data/inter_class_similarities.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(inter_class_similarities, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94984a",
   "metadata": {},
   "source": [
    "## Osztályleírások és képek hasonlóságának mérése\n",
    "\n",
    "Minden osztályhoz tartozó szöveg alapján kiszámoljuk a legjobban egyező kép cosine similarity értékét az embeddingek között.  \n",
    "Ezt ha ezen futtatjuk: `short_custom_captions.json` látható, hogy egy rövid mondat semmiképp sem lesz elég."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-1 similarity számolása: 100%|██████████| 102/102 [00:01<00:00, 94.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  top1_similarity\n",
      "0         1          0.02080\n",
      "1         2          0.02340\n",
      "2         3          0.00329\n",
      "3         4          0.02044\n",
      "4         5          0.00179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények tárolása\n",
    "top1_results = []\n",
    "\n",
    "# Végigmegyünk mind a 102 osztályon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Top-1 similarity számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg → embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Top-1 érték kinyerése\n",
    "    top1_score = similarities.max().item()\n",
    "\n",
    "    top1_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"top1_similarity\": round(top1_score, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tesszük\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "print(df_top1.head())\n",
    "\n",
    "# CSV-be mentés (ha szeretnéd)\n",
    "df_top1.to_csv(\"../data/class_top1_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222a25c",
   "metadata": {},
   "source": [
    "## Precision@N számítása osztályonként\n",
    "\n",
    "Minden osztály leírása alapján kiszámoljuk, hogy az embeddingek közül a hozzá tartozó képek közül hány jelenik meg a legjobban illeszkedők között. Az N értéke az adott osztályhoz tartozó képek száma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision@N számolása: 100%|██████████| 102/102 [00:01<00:00, 72.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  correct_in_topN  precision_at_class_size\n",
      "0         1          27               20                  0.74074\n",
      "1         2          49               40                  0.81633\n",
      "2         3          36               25                  0.69444\n",
      "3         4          44               39                  0.88636\n",
      "4         5          54               39                  0.72222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények tárolása\n",
    "precision_results = []\n",
    "\n",
    "# Végigmegyünk mind a 102 osztályon\n",
    "for class_id in tqdm(range(1, 103), desc=\"Precision@N számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg → embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "\n",
    "    # Az adott osztályhoz tartozó képek száma\n",
    "    class_size = sum(1 for info in infos if int(info[\"label\"]) == class_id)\n",
    "\n",
    "    # Top N visszakeresés (N = class_size)\n",
    "    top_indices = similarities.topk(class_size).indices\n",
    "\n",
    "    # Ezzel nézzük meg hány top kép van a class_id osztályban\n",
    "    correct = sum(1 for idx in top_indices if int(infos[idx][\"label\"]) == class_id)\n",
    "\n",
    "    precision = correct / class_size if class_size > 0 else 0.0\n",
    "\n",
    "    precision_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        \"correct_in_topN\": correct,\n",
    "        \"precision_at_class_size\": round(precision, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame-be tesszük\n",
    "df_precision = pd.DataFrame(precision_results)\n",
    "print(df_precision.head())\n",
    "\n",
    "# CSV mentés\n",
    "df_precision.to_csv(\"../data/class_precision_at_class_size.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728db919",
   "metadata": {},
   "source": [
    "## Recall@X% küszöbértékek számítása\n",
    "\n",
    "Minden osztály esetén meghatározzuk, hogy hány \"legjobb\" kép szükséges ahhoz, hogy az osztályhoz tartozó képek 70%, 80%, 90% és 95%-át visszakeressük. Emellett elmentjük a megfelelő cosine similarity küszöbértékeket is, amelyek ezeket az arányokat biztosítják."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386dc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\944431738.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "Recall cutoff számolása: 100%|██████████| 102/102 [00:04<00:00, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_size  topN_70  topN_80  topN_90  topN_95  threshold_70  \\\n",
      "0         1          27       26       34       50       51       0.13915   \n",
      "1         2          49       37       45       75       86       0.09562   \n",
      "2         3          36       39       47       67      227       0.11541   \n",
      "3         4          44       32       39       45       52       0.12268   \n",
      "4         5          54       50       80       90      114       0.11872   \n",
      "\n",
      "   threshold_80  threshold_90  threshold_95  \n",
      "0       0.13033       0.11447       0.11366  \n",
      "1       0.08807       0.07893       0.07664  \n",
      "2       0.11272       0.10759       0.08375  \n",
      "3       0.11493       0.10914       0.10568  \n",
      "4       0.11281       0.11144       0.10730  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Kimenet tárolása\n",
    "recall_results = []\n",
    "\n",
    "# Osztályonként végigmegyünk\n",
    "for class_id in tqdm(range(1, 103), desc=\"Recall cutoff számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Text embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity az összes képre\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze()\n",
    "    sorted_indices = torch.argsort(similarities, descending=True)\n",
    "\n",
    "    # Bináris vektor: 1, ha helyes osztályba tartozik\n",
    "    binary_hits = [1 if int(infos[i][\"label\"]) == class_id else 0 for i in sorted_indices]\n",
    "    cumsum_hits = np.cumsum(binary_hits) # a visszakeresett listában hány jó találat van eddig összesítve\n",
    "\n",
    "    class_size = sum(binary_hits)  # az adott osztályhoz tartozó képek száma\n",
    "    recall_targets = {\n",
    "        70: int(np.ceil(class_size * 0.70)),\n",
    "        80: int(np.ceil(class_size * 0.80)),\n",
    "        90: int(np.ceil(class_size * 0.90)),\n",
    "        95: int(np.ceil(class_size * 0.95)),\n",
    "    }\n",
    "\n",
    "    topN_at = {}\n",
    "    threshold_at = {}\n",
    "\n",
    "    for perc, target in recall_targets.items():\n",
    "        found_index = next((i for i, val in enumerate(cumsum_hits) if val >= target), None) # keressük azt az első olyan indexet, ahol már elértük vagy túlléptük a kívánt számú helyes találatot\n",
    "        if found_index is not None:\n",
    "            topN_at[f\"topN_{perc}\"] = found_index + 1  # index → N\n",
    "            threshold_at[f\"threshold_{perc}\"] = round(similarities[sorted_indices[found_index]].item(), 5)\n",
    "        else:\n",
    "            topN_at[f\"topN_{perc}\"] = None\n",
    "            threshold_at[f\"threshold_{perc}\"] = None\n",
    "\n",
    "    result = {\n",
    "        \"class_id\": class_id,\n",
    "        \"class_size\": class_size,\n",
    "        **topN_at,\n",
    "        **threshold_at\n",
    "    }\n",
    "\n",
    "    recall_results.append(result)\n",
    "\n",
    "# Eredmények táblázatba\n",
    "df_recall = pd.DataFrame(recall_results)\n",
    "print(df_recall.head())\n",
    "\n",
    "# Mentés CSV-be\n",
    "df_recall.to_csv(\"../data/class_recall_cutoffs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965c89a",
   "metadata": {},
   "source": [
    "## Average Precision számítása\n",
    "\n",
    "Minden osztály esetén kiszámoljuk az osztályhoz tartozó képek visszakeresésének average precision értékét a cosine similarity alapján. A végén kiszámoljuk a teljes rendszerre vonatkozó mAP értéket is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_embeddings_siglip.pt\")\n",
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_17880\\4052214356.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  infos = torch.load(\"C:/Users/Adam/Desktop/applied_ml/dataset/image_info_siglip.pt\")\n",
      "AP számolása: 100%|██████████| 102/102 [00:02<00:00, 39.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  average_precision\n",
      "0         1            0.79286\n",
      "1         2            0.91528\n",
      "2         3            0.78243\n",
      "3         4            0.96496\n",
      "4         5            0.81550\n",
      "\n",
      "Mean Average Precision (mAP): 0.87911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Eredmények\n",
    "ap_results = []\n",
    "\n",
    "for class_id in tqdm(range(1, 103), desc=\"AP számolása\"):\n",
    "    str_id = str(class_id)\n",
    "    lines = class_texts[str_id]\n",
    "    full_text = \" \".join(lines)\n",
    "\n",
    "    # Szöveg embedding\n",
    "    inputs = processor(text=[full_text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_feat = model.get_text_features(**inputs)\n",
    "        text_feat = text_feat / text_feat.norm(p=2, dim=-1, keepdim=True)\n",
    "        text_feat = text_feat.cpu()\n",
    "\n",
    "    # Cosine similarity\n",
    "    similarities = torch.matmul(embeddings, text_feat.T).squeeze().numpy()\n",
    "\n",
    "    # Binary ground truth: 1 ha jó osztály, különben 0\n",
    "    gt_labels = [1 if int(info[\"label\"]) == class_id else 0 for info in infos]\n",
    "\n",
    "    # Average precision\n",
    "    if sum(gt_labels) > 0:\n",
    "        ap = average_precision_score(gt_labels, similarities)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"class_id\": class_id,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\nMean Average Precision (mAP): {round(mean_ap, 5)}\")\n",
    "\n",
    "# CSV mentés\n",
    "df_ap.to_csv(\"../data/class_average_precision.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455f70c",
   "metadata": {},
   "source": [
    "## Kép-alapú top-1 hasonlóság számítása\n",
    "\n",
    "Kiszámoljuk az összes kép cosine similarity mátrixát, majd minden képhez meghatározzuk a legjobban hasonlító másik képet (önmagát kizárva). Megnézzük, hogy ez a top-1 kép azonos osztályba tartozik-e?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-1 keresés képenként: 100%|██████████| 6552/6552 [00:00<00:00, 148134.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix (n x n)\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagonálisan 1-es lenne (önmagával) – ezt kilőjük\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredmények tárolása\n",
    "top1_results = []\n",
    "\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Top-1 keresés képenként\"):\n",
    "    top1_idx = sim_matrix[i].argmax()\n",
    "    top1_sim = sim_matrix[i][top1_idx]\n",
    "\n",
    "    label_i = int(infos[i][\"label\"])\n",
    "    label_top1 = int(infos[top1_idx][\"label\"])\n",
    "    same_class = (label_i == label_top1)\n",
    "\n",
    "    top1_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"top1_index\": top1_idx,\n",
    "        \"top1_similarity\": round(top1_sim, 5),\n",
    "        \"label\": label_i,\n",
    "        \"top1_label\": label_top1,\n",
    "        \"same_class\": same_class\n",
    "    })\n",
    "\n",
    "# Mentés\n",
    "df_top1 = pd.DataFrame(top1_results)\n",
    "df_top1.to_csv(\"../data/image_top1_similarity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca228c",
   "metadata": {},
   "source": [
    "## Kép-alapú Recall@K számítása\n",
    "\n",
    "Minden kép esetén meghatározzuk, hogy a K legjobban hasonlító képből hány tartozik azonos osztályba. Ezt különböző K értékekre (1, 5, 10, 20) számoljuk ki.  \n",
    "Itt azért olyan kicsik az értékek mindig, mert az i-edik kép osztályának létszámával osztunk (-1, mert i nincs benne). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recall képenként: 100%|██████████| 6552/6552 [00:06<00:00, 1051.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Átlagos Recall@K értékek:\n",
      "Recall@1: 0.01568\n",
      "Recall@5: 0.07727\n",
      "Recall@10: 0.15266\n",
      "Recall@20: 0.29798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix (n x n)\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Diagonálisan -1, hogy önmagát ne hozza vissza\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Recall@K értékek\n",
    "K_values = [1, 5, 10, 20]\n",
    "recall_records = []\n",
    "\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"Recall képenként\"):\n",
    "    true_label = int(infos[i][\"label\"])\n",
    "    top_indices = np.argsort(-sim_matrix[i])  # csökkenő sorrend\n",
    "\n",
    "    recalls = {}\n",
    "    # Az aktuális osztályhoz tartozó képek száma (önmagát kivéve)\n",
    "    total_same_class = sum(1 for j in range(len(infos)) if j != i and int(infos[j][\"label\"]) == true_label)\n",
    "\n",
    "    for k in K_values:\n",
    "        top_k = top_indices[:k]\n",
    "        correct = sum(1 for j in top_k if int(infos[j][\"label\"]) == true_label)\n",
    "        recall = correct / total_same_class if total_same_class > 0 else 0.0\n",
    "        recalls[f\"recall@{k}\"] = round(recall, 5)\n",
    "\n",
    "    recall_records.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": true_label,\n",
    "        **recalls\n",
    "    })\n",
    "\n",
    "# DataFrame mentés\n",
    "df_recall = pd.DataFrame(recall_records)\n",
    "df_recall.to_csv(\"../data/image_recall_at_k.csv\", index=False)\n",
    "\n",
    "# Átlag recall@k kiírás\n",
    "mean_recalls = df_recall[[f\"recall@{k}\" for k in K_values]].mean()\n",
    "print(\"\\nÁtlagos Recall@K értékek:\")\n",
    "for k in K_values:\n",
    "    print(f\"Recall@{k}: {round(mean_recalls[f'recall@{k}'], 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386731d3",
   "metadata": {},
   "source": [
    "## Kép-alapú Average Precision számítása\n",
    "\n",
    "Minden kép esetén kiszámoljuk, hogy a hozzá hasonlító többi kép mennyire jól sorolja előre az azonos osztályúakat a cosine similarity alapján. Az önmagával való hasonlóságot kizárjuk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AP per image: 100%|██████████| 6552/6552 [00:18<00:00, 352.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_index  label  average_precision\n",
      "0            0      1            0.80528\n",
      "1            1      1            0.80784\n",
      "2            2      1            0.80397\n",
      "3            3      1            0.79885\n",
      "4            4      1            0.77852\n",
      "\n",
      "Mean Average Precision (mAP) for images: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity mátrix\n",
    "embedding_matrix = embeddings.numpy()\n",
    "sim_matrix = cosine_similarity(embedding_matrix)\n",
    "\n",
    "# Saját magát nem hasonlítjuk (AP-ben nincs értelme)\n",
    "np.fill_diagonal(sim_matrix, -1)\n",
    "\n",
    "# Eredmények\n",
    "ap_results = []\n",
    "\n",
    "for i in tqdm(range(sim_matrix.shape[0]), desc=\"AP per image\"):\n",
    "    label = int(infos[i][\"label\"])\n",
    "\n",
    "    # Ground truth: 1 ha ugyanabba az osztályba tartozik, különben 0 (önmagát nem számítjuk)\n",
    "    gt = np.array([1 if int(infos[j][\"label\"]) == label else 0 for j in range(len(infos))])\n",
    "    gt[i] = 0  # önmagát nullázzuk\n",
    "\n",
    "    scores = sim_matrix[i]\n",
    "\n",
    "    if gt.sum() > 0:\n",
    "        ap = average_precision_score(gt, scores)\n",
    "    else:\n",
    "        ap = 0.0\n",
    "\n",
    "    ap_results.append({\n",
    "        \"image_index\": i,\n",
    "        \"label\": label,\n",
    "        \"average_precision\": round(ap, 5)\n",
    "    })\n",
    "\n",
    "# DataFrame + mAP\n",
    "df_ap = pd.DataFrame(ap_results)\n",
    "mean_ap = df_ap[\"average_precision\"].mean()\n",
    "print(df_ap.head())\n",
    "print(f\"\\nMean Average Precision (mAP) for images: {round(mean_ap, 5)}\")\n",
    "\n",
    "# Mentés\n",
    "df_ap.to_csv(\"../data/image_average_precision.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
